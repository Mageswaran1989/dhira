{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "- python -m spacy download en\n",
    "- python -m spacy download en_core_web_md\n",
    "- python -m spacy download parser\n",
    "- python -m spacy download glove\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this's spacy tokenize test\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"this's spacy tokenize test\")\n",
    "print(doc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "'s\n",
      "spacy\n",
      "tokenize\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenize Test or Sentence Segmentation Test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"this is spacy sentence tokenize test. this is second sent! is this the third sent? final test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is spacy sentence tokenize test.\n",
      "this is second sent!\n",
      "is this the third sent? final test.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"this is spacy lemmatize testing. programming books are more better than others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this 552 this\n",
      "is 536 be\n",
      "spacy 776980 spacy\n",
      "lemmatize 776982 lemmatize\n",
      "testing 4191 testing\n",
      ". 453 .\n",
      "programming 2171 programming\n",
      "books 1300 book\n",
      "are 536 be\n",
      "more 597 more\n",
      "better 761 better\n",
      "than 626 than\n",
      "others 655 other\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token, token.lemma, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pos Tagging Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " doc4 = nlp(u\"This is pos tagger test for spacy pos tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 88 DET\n",
      "is 98 VERB\n",
      "pos 82 ADJ\n",
      "tagger 90 NOUN\n",
      "test 90 NOUN\n",
      "for 83 ADP\n",
      "spacy 90 NOUN\n",
      "pos 90 NOUN\n",
      "tagger 90 NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print(token, token.pos, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognizer (NER) Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc5 = nlp(u\"Rami Eid is studying at Stony Brook University in New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rami Eid 377 PERSON\n",
      "Stony Brook University 380 ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in doc5.ents:\n",
    "    print(ent, ent.label, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Chunk Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc6 = nlp(u\"Natural language processing (NLP) deals with the application of computational models to text or speech data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) deals\n",
      "the application\n",
      "computational models\n",
      "text or speech data\n"
     ]
    }
   ],
   "source": [
    "for np in doc6.noun_chunks:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "doc7 = nlp(u\"Apples and oranges are similar. Boots and hippos aren't.\")\n",
    "apples = doc7[0]\n",
    "oranges = doc7[2]\n",
    "boots = doc7[6]\n",
    "hippos = doc7[8]\n",
    "print(apples.similarity(oranges))\n",
    "print(boots.similarity(hippos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
