{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- http://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "- http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "- Keras: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MLP for the IMDB problem\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 6000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "y = numpy.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "# summarize size\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of classes\n",
    "print(\"Classes: \")\n",
    "print(numpy.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "5998\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of words\n",
    "print(\"Number of words: \")\n",
    "print(len(numpy.unique(numpy.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9766433be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 32)           192000    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,192,501\n",
      "Trainable params: 4,192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words)) # 6000(vocab size/top_words) * 32 = 192000 params\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "77s - loss: 0.5340 - acc: 0.6817 - val_loss: 0.3133 - val_acc: 0.8634\n",
      "Epoch 2/2\n",
      "84s - loss: 0.1970 - acc: 0.9233 - val_loss: 0.3127 - val_acc: 0.8695\n",
      "Accuracy: 86.95%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for the IMDB problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           192000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,195,605\n",
      "Trainable params: 2,195,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "95s - loss: 0.1289 - acc: 0.9553 - val_loss: 0.3143 - val_acc: 0.8816\n",
      "Epoch 2/5\n",
      "70s - loss: 0.0609 - acc: 0.9836 - val_loss: 0.3828 - val_acc: 0.8741\n",
      "Epoch 3/5\n",
      "70s - loss: 0.0202 - acc: 0.9970 - val_loss: 0.4832 - val_acc: 0.8722\n",
      "Epoch 4/5\n",
      "70s - loss: 0.0049 - acc: 0.9997 - val_loss: 0.5604 - val_acc: 0.8739\n",
      "Epoch 5/5\n",
      "99s - loss: 0.0015 - acc: 0.9999 - val_loss: 0.6081 - val_acc: 0.8750\n",
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 1610s - loss: 0.5471 - acc: 0.7032 - val_loss: 0.3233 - val_acc: 0.8661\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 1375s - loss: 0.2932 - acc: 0.8803 - val_loss: 0.2968 - val_acc: 0.8785\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 1721s - loss: 0.2294 - acc: 0.9108 - val_loss: 0.2986 - val_acc: 0.8824\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.24%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
