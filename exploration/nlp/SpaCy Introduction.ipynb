{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "- python -m spacy download en\n",
    "- python -m spacy download en_core_web_md\n",
    "- python -m spacy download parser\n",
    "- python -m spacy download glove\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this's spacy tokenize test\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"this's spacy tokenize test\")\n",
    "print(doc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "'s\n",
      "spacy\n",
      "tokenize\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenize Test or Sentence Segmentation Test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"this is spacy sentence tokenize test. this is second sent! is this the third sent? final test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is spacy sentence tokenize test.\n",
      "this is second sent!\n",
      "is this the third sent?\n",
      "final test.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"this is spacy lemmatize testing. programming books are more better than others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this 530 this\n",
      "is 522 be\n",
      "spacy 173815 spacy\n",
      "lemmatize 1484778 lemmatize\n",
      "testing 2933 testing\n",
      ". 453 .\n",
      "programming 3441 programming\n",
      "books 1045 book\n",
      "are 522 be\n",
      "more 563 more\n",
      "better 649 better\n",
      "than 589 than\n",
      "others 598 other\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token, token.lemma, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pos Tagging Test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.winwaed.com/blog/2011/11/08/part-of-speech-tags/  \n",
    "http://www.clips.ua.ac.be/pages/mbsp-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " doc4 = nlp(u\"This is pos tagger test for spacy pos tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 88 DET\n",
      "is 98 VERB\n",
      "pos 82 ADJ\n",
      "tagger 90 NOUN\n",
      "test 90 NOUN\n",
      "for 83 ADP\n",
      "spacy 90 NOUN\n",
      "pos 90 NOUN\n",
      "tagger 90 NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print(token, token.pos, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognizer (NER) Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc5 = nlp(u\"Rami Eid is studying at Stony Brook University in New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rami Eid 377 PERSON\n",
      "Stony Brook University 380 ORG\n",
      "New York 381 GPE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc5.ents:\n",
    "    print(ent, ent.label, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Chunk Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc6 = nlp(u\"Natural language processing (NLP) deals with the application of computational models to text or speech data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) deals\n",
      "the application\n",
      "computational models\n",
      "text\n",
      "speech\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "for np in doc6.noun_chunks:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77809414836\n",
      "0.038474555379\n"
     ]
    }
   ],
   "source": [
    "doc7 = nlp(u\"Apples and oranges are similar. Boots and hippos aren't.\")\n",
    "apples = doc7[0]\n",
    "oranges = doc7[2]\n",
    "boots = doc7[6]\n",
    "hippos = doc7[8]\n",
    "print(apples.similarity(oranges))\n",
    "print(boots.similarity(hippos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-threaded generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = [u'One document.', u'...', u'Lots of documents']\n",
    "# .pipe streams input, and produces streaming output\n",
    "iter_texts = (texts[i % 3] for i in range(100000000))\n",
    "for i, doc in enumerate(nlp.pipe(iter_texts, batch_size=50, n_threads=4)):\n",
    "    assert doc.is_parsed\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apples"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
