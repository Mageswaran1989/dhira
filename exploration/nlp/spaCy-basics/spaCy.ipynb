{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the language model. Here en refers to default english Model.\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = unicode(open('reviews.txt').read().decode('utf8'))\n",
    "document = nlp(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features of Document Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__iter__',\n",
       " '__len__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_py_tokens',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'has_vector',\n",
       " 'is_parsed',\n",
       " 'is_tagged',\n",
       " 'mem',\n",
       " 'merge',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'read_bytes',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'similarity',\n",
       " 'string',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The document has following features.\n",
    "dir(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features of Token Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'has_repvec',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ancestor_of',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'repvec',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sentiment',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'string',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iterative tokens: Every spacy document is tokenized.\n",
    "dir(document[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc attribute\n",
    "- doc.sents: iterable for sentences in the document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The boy saw the yellow dog.,\n",
       " Nice place.,\n",
       " Better than some reviews give it credit for.,\n",
       " Overall, the rooms were a bit small but nice.,\n",
       " Everything was clean, the view was wonderful and it is very well located (the Prudential Center makes shopping and eating easy and the T is nearby for jaunts out and about the city).]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentences treated like list of strings.\n",
    "list(document.sents)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS: Part of Speech for each token\n",
    "- Coarse Grained: The general POS tag => token.pos_\n",
    "- Fine Grained: More specific POS tag => toke.tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Coarse-POS and corresponding Fine-POS tag in the document.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'$': u'SYM',\n",
       " u\"''\": u'PUNCT',\n",
       " u',': u'PUNCT',\n",
       " u'-LRB-': u'PUNCT',\n",
       " u'-RRB-': u'PUNCT',\n",
       " u'.': u'PUNCT',\n",
       " u':': u'PUNCT',\n",
       " u'ADD': u'X',\n",
       " u'AFX': u'ADJ',\n",
       " u'CC': u'CCONJ',\n",
       " u'CD': u'NUM',\n",
       " u'DT': u'DET',\n",
       " u'EX': u'ADV',\n",
       " u'FW': u'X',\n",
       " u'HYPH': u'PUNCT',\n",
       " u'IN': u'ADP',\n",
       " u'JJ': u'ADJ',\n",
       " u'JJR': u'ADJ',\n",
       " u'JJS': u'ADJ',\n",
       " u'LS': u'PUNCT',\n",
       " u'MD': u'VERB',\n",
       " u'NFP': u'PUNCT',\n",
       " u'NN': u'NOUN',\n",
       " u'NNP': u'PROPN',\n",
       " u'NNPS': u'PROPN',\n",
       " u'NNS': u'NOUN',\n",
       " u'PDT': u'ADJ',\n",
       " u'POS': u'PART',\n",
       " u'PRP': u'PRON',\n",
       " u'PRP$': u'ADJ',\n",
       " u'RB': u'ADV',\n",
       " u'RBR': u'ADV',\n",
       " u'RBS': u'ADV',\n",
       " u'RP': u'PART',\n",
       " u'SP': u'SPACE',\n",
       " u'SYM': u'SYM',\n",
       " u'TO': u'PART',\n",
       " u'UH': u'INTJ',\n",
       " u'VB': u'VERB',\n",
       " u'VBD': u'VERB',\n",
       " u'VBG': u'VERB',\n",
       " u'VBN': u'VERB',\n",
       " u'VBP': u'VERB',\n",
       " u'VBZ': u'VERB',\n",
       " u'WDT': u'ADJ',\n",
       " u'WP': u'NOUN',\n",
       " u'WP$': u'ADJ',\n",
       " u'WRB': u'ADV',\n",
       " u'XX': u'X',\n",
       " u'``': u'PUNCT'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('All the Coarse-POS and corresponding Fine-POS tag in the document.')\n",
    "all_tags = {w.tag_: w.pos_ for w in document}\n",
    "all_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# token.tag_ : Specific POS tag\n",
    "## Fine-Grained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DT boy NN saw VBD the DT yellow JJ dog NN . . \r\n",
      " SP\n",
      "Nice JJ place NN . .\n",
      "Better RBR than IN some DT reviews NNS give VBP it PRP credit NN for IN . .\n",
      "Overall RB , , the DT rooms NNS were VBD a DT bit NN small JJ but CC nice JJ . .\n",
      "Everything NN was VBD clean JJ , , the DT view NN was VBD wonderful JJ and CC it PRP is VBZ very RB well RB located JJ ( -LRB- the DT Prudential NNP Center NNP makes VBZ shopping NN and CC eating VBG easy JJ and CC the DT T NN is VBZ nearby JJ for IN jaunts NNS out RB and CC about IN the DT city NN ) -RRB- . .\n"
     ]
    }
   ],
   "source": [
    "#The POS tags for each word from first 5 sentences of our document.\n",
    "for sents in list(document.sents)[:5]:\n",
    "    for word in sents:\n",
    "        print word,word.tag_,\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# token.pos_ : General POS tag\n",
    "## Coarse-Grained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET boy NOUN saw VERB the DET yellow ADJ dog NOUN . PUNCT \r\n",
      " SPACE\n",
      "Nice ADJ place NOUN . PUNCT\n",
      "Better ADV than ADP some DET reviews NOUN give VERB it PRON credit NOUN for ADP . PUNCT\n",
      "Overall ADV , PUNCT the DET rooms NOUN were VERB a DET bit NOUN small ADJ but CCONJ nice ADJ . PUNCT\n",
      "Everything NOUN was VERB clean ADJ , PUNCT the DET view NOUN was VERB wonderful ADJ and CCONJ it PRON is VERB very ADV well ADV located ADJ ( PUNCT the DET Prudential PROPN Center PROPN makes VERB shopping NOUN and CCONJ eating VERB easy ADJ and CCONJ the DET T NOUN is VERB nearby ADJ for ADP jaunts NOUN out ADV and CCONJ about ADP the DET city NOUN ) PUNCT . PUNCT\n"
     ]
    }
   ],
   "source": [
    "#pos_ gives the general POS than tag_.\n",
    "for sents in list(document.sents)[:5]:\n",
    "    for word in sents:\n",
    "        print word,word.pos_,\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Class Attributes\n",
    "- token.lemma: (int) Base form of a word.\n",
    "- token.lemma_: (unicode) Base form of a word.\n",
    "- token.tag: (int) Fine-grained part-of-speech.\n",
    "- token.tag_: (unicode)Fine-grained part-of-speech.\n",
    "- token.pos: (int) Coarse-rained POS.\n",
    "- token.pos_: (unicode) Coarse-grained POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 501 the 460 DT 88 DET\n",
      "boy 2729 boy 474 NN 90 NOUN\n",
      "saw 678 see 489 VBD 98 VERB\n",
      "the 501 the 460 DT 88 DET\n",
      "yellow 6056 yellow 467 JJ 82 ADJ\n",
      "dog 1847 dog 474 NN 90 NOUN\n",
      ". 453 . 453 . 95 PUNCT\n",
      "\r\n",
      "1014 \r\n",
      "485 SP 101 SPACE\n",
      "Nice 1147 nice 467 JJ 82 ADJ\n",
      "place 983 place 474 NN 90 NOUN\n"
     ]
    }
   ],
   "source": [
    "for word in document[:10]:\n",
    "    print word.text, word.lemma, word.lemma_, word.tag, word.tag_, word.pos, word.pos_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token attributes\n",
    "- token.text: the text\n",
    "- token.is_stop: stopword flag\n",
    "- token.sentiment: scalar val indicating the +vity or -vitiy of the token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The True 0.0\n",
      "boy False 0.0\n",
      "saw False 0.0\n",
      "the True 0.0\n",
      "yellow False 0.0\n",
      "dog False 0.0\n",
      ". False 0.0\n",
      "\r\n",
      "False 0.0\n",
      "Nice False 0.0\n",
      "place False 0.0\n"
     ]
    }
   ],
   "source": [
    "for word in document[:10]:\n",
    "    print word.text, word.is_stop, word.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token attributes\n",
    "- token.lower_: lowercase (token)\n",
    "- token.is_punct: punctuation flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'hotel', 685),\n",
       " (u'room', 653),\n",
       " (u'\\r\\n', 331),\n",
       " (u'great', 300),\n",
       " (u'sheraton', 286)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#more attributes \n",
    "from collections import Counter\n",
    "cleaned_list = [word.lower_ for word in document if not word.is_stop and not word.is_punct]\n",
    "Counter(cleaned_list) .most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recog - doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n",
      "2900\n"
     ]
    }
   ],
   "source": [
    "'''Entities can be of different types,\n",
    "such as – person, location, organization, dates, numerals, etc.'''\n",
    "#Doc.ents is a property to iterate over the entities in the document.\n",
    "entities = [ent for ent in document.ents]  \n",
    "d = {each.string.lower():each.label_ for each in entities}\n",
    "print len(d)\n",
    "print len(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntactic Dependency - token.head\n",
    "- Syntactic dependency by Dependency Parsing using tokens.\n",
    "- token.head gives the master for the token.\n",
    "- The (finite) verb is taken to be the structural center of clause structure i.e. ROOT.\n",
    "- So to traverse the dependency tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> [The, boy, boy, saw]\n",
      "boy --> [boy, saw]\n",
      "saw --> []\n",
      "the --> [the, dog, dog, saw]\n",
      "yellow --> [yellow, dog, dog, saw]\n",
      "dog --> [dog, saw]\n",
      ". --> [., saw]\n",
      "\r\n",
      " --> [\r\n",
      ", ., ., saw]\n",
      "Nice --> [Nice, place]\n",
      "place --> []\n",
      "-----------------------------------------------------------------\n",
      "The (finite) verb is taken to be the structural center of clause structure i.e. ROOT.\n",
      "-----------------------------------------------------------------\n",
      "The-det-> boy-nsubj-> boy-nsubj-> saw-ROOT\n",
      "boy-nsubj-> saw-ROOT\n",
      "\n",
      "the-det-> dog-dobj-> dog-dobj-> saw-ROOT\n",
      "yellow-amod-> dog-dobj-> dog-dobj-> saw-ROOT\n",
      "dog-dobj-> saw-ROOT\n",
      ".-punct-> saw-ROOT\n",
      "\r\n",
      "--> .-punct-> .-punct-> saw-ROOT\n",
      "Nice-compound-> place-ROOT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_root(token):\n",
    "    \"\"\"\n",
    "    Walk up the syntactic tree, collecting tokens to the root of the given `token`.\n",
    "    :param token: Spacy token\n",
    "    :return: list of Spacy tokens\n",
    "    \"\"\"\n",
    "    tokens_to_r = []\n",
    "    while token.head is not token:\n",
    "        tokens_to_r.append(token)\n",
    "        token = token.head\n",
    "        tokens_to_r.append(token)\n",
    "\n",
    "    return tokens_to_r\n",
    "\n",
    "# For first 10 tokens in document, print their tokens up till the root\n",
    "for token in document[:10]:\n",
    "    print('{} --> {}'.format(token, tokens_to_root(token)))\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "print('The (finite) verb is taken to be the structural center of clause structure i.e. ROOT.')\n",
    "print('-----------------------------------------------------------------')\n",
    "# Print dependency labels of the tokens\n",
    "for token in document[:10]:\n",
    "    print('-> '.join(['{}-{}'.format(dependent_token, dependent_token.dep_) for dependent_token in tokens_to_root(token)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun-Chunks\n",
    "#### What is a Noun Chunk?\n",
    "Noun chunks are the phrases based upon nouns recovered from tokenized text using the speech tags.\n",
    "\n",
    "Example:\n",
    "\n",
    "The sentence \"The boy saw the yellow dog\" has 2 noun objects, the boy and the dog. \n",
    "Therefore the noun chunks will be\n",
    "\n",
    "\t1. \"The boy\"\n",
    "\t2. \"the yellow dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The boy, the yellow dog, Nice place, some reviews, credit, the rooms, Everything, the view, it, the Prudential Center]\n"
     ]
    }
   ],
   "source": [
    "#The first \n",
    "print([chunk for chunk in document.noun_chunks][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
